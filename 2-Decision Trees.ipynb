{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisionn Trees\n",
    "![](picture/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if every item in the dataset is in the same class:\n",
    "\n",
    "    if so return the class label\n",
    "    Else\n",
    "        find the best feature to split the data\n",
    "        split the dataset\n",
    "        create a branch node\n",
    "             for each split\n",
    "                 call createBranch and add the result to the branch node\n",
    "             retuen branch node\n",
    "             \n",
    "Please note the recursive nature of createBranch. It calls itself in the second-to-last line.\n",
    "\n",
    "**Note:** some decision trees make a binary split of the data,but we won't do this. We'll follow the ID3 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 ID3\n",
    "\n",
    "Entropy is defined as the expected value of the information. First, we need to define information. If you’re classifying something that can take on multiple values, the information for symbol xi is defined as\n",
    "\n",
    "$l(x_i) = log_{2}p(x_i)$\n",
    "\n",
    "where p(xi) is the probability of choosing this class.\n",
    "\n",
    "To calculate entropy, you need the expected value of all the information of all pos-\n",
    "sible values of our class. This is given by\n",
    "\n",
    "$H = - \\sum_{i=1}^{n}p(x_i)log_{2}p(x_i)$\n",
    "\n",
    "where n is the number of classes.\n",
    "\n",
    "Note: click [here](https://blog.csdn.net/acdreamers/article/details/44661149) to ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "\n",
    "See the data in table 3.1. It contains five animals pulled from the sea and asks if they can survive without coming to the surface and if they have flippers. We would like to classify these animals into two classes: fish and not fish. Now we want to decide whether we should split the data based on the first feature or the second feature. To answer this question, we need some quantitative way of determining how to split the data. We’ll discuss that next.\n",
    "\n",
    "![](picture/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let's look how to compute SannonENT\n",
    "\n",
    "If we target learning \"is Fish?\".\n",
    "\n",
    "The table 3.1 total examples is 5, and 2 \"yes\",3 \"no\". So,we compute shannonENT as follows\n",
    "\n",
    "$H = - \\frac{3}{5} log_{2}\\frac{3}{5} - \\frac{2}{5} log_{2} \\frac{2}{5} = 0.9709505944546686$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You’ll stop under the following conditions: you run out of attributes on which to split or all the instances in a branch are the same class. If all instances have the same class, then you’ll create a leaf node, or terminating block. Any data that reaches this leaf node is deemed to belong to the class of that leaf node. \n",
    "![](picture/03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Befor we create the Decision Tree,we need learning decision tree's logist.\n",
    "\n",
    "Let's look what is decision tree's logist.\n",
    "\n",
    "We using this example dataset\n",
    "\n",
    "![](picture/04.png)\n",
    "\n",
    "\n",
    "- step 1: we need compute Entropy(Fish) = $- \\frac{3}{5} log_{2}\\frac{3}{5} - \\frac{2}{5} log_{2} \\frac{2}{5}=0.9709505944546686$\n",
    "- step 2: comput IG\n",
    "    - No surfacing:\n",
    "        - 1:[is Fish] yes,yes,no \n",
    "        - 0:[is Fish] no,no\n",
    "        - Entropy(1) = $- \\frac{2}{3} log_{2}\\frac{2}{3} - \\frac{1}{3} log_{2} \\frac{1}{3}=0.918296 $\n",
    "        - Entropy(0) = $- 0 - \\frac{2}{2} log_{2} \\frac{2}{2}=0 $\n",
    "        - Entropy(No surfacing | Fish) = $\\frac{3}{5}\\times 0.918296 + \\frac{2}{5} \\times 0 = 0.5509$\n",
    "        - $\\frac{3}{5},\\frac{2}{5}$: in total dataset\n",
    "        - IG(No surfacing | Fish) = 0.9709505944546686 - 0.5509 = 0.42\n",
    "    - Flippers:\n",
    "        - 1:[is Fish] yes,yes,no,no\n",
    "        - 0:[is Fish] no\n",
    "        - Entropy(1) = $- \\frac{2}{4} log_{2}\\frac{2}{4} - \\frac{2}{4} log_{2} \\frac{2}{4}=1.0 $\n",
    "        - Entropy(0) = $- 0 - \\frac{1}{1} log_{2} \\frac{1}{1}=0 $\n",
    "        - Entropy(Flippers | Fish) = $\\frac{4}{5}\\times 1 + \\frac{1}{5} \\times 0 = 0.8$\n",
    "        - $\\frac{1}{5},\\frac{4}{5}$: in total dataset\n",
    "        - IG(Flippers | Fish) = 0.9709505944546686 - 0.8 = 0.17095\n",
    "        \n",
    "- step 3: choose best IG(max IG)\n",
    "    - so,we choose feature \"No surfacing\".\n",
    "- step 4: using feature \"No surfacing\" to split dataset.\n",
    "- step 5: repeat like setp 1-3\n",
    "    \n",
    "**Last Note:**\n",
    " - if best feature can't split dataset to  have same class label, then ,can using other feature to split dataset.\n",
    "     - [[1, 1, 'yes'], [1, 0, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]\n",
    " \n",
    " - if case have no more features to split, but we also can't split dataset to have same class label, then we use \"majority vote.\"\n",
    "     - [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Build Decision Trees\n",
    "\n",
    "在构建之间我们需要明白几件事:\n",
    "\n",
    "- 1.在代码中是需要计算标签的经验熵,直接选取各个特征下的信息熵最小的也就是信息增益最大的特征,因为我们做的是$IG=H(y)-H(features)$\n",
    "\n",
    "- 2.每次计算各个feature的不同熵的时候,实际上还是计算各个feature划分后数据的labels信息熵\n",
    "\n",
    "- 3.为了计算方便,我们会使用[pandas](https://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset():\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        dataSet: data set\n",
    "        labels: data label\n",
    "    Note:\n",
    "    ----\n",
    "        y: yes\n",
    "        n: no\n",
    "        last columns is labels.\n",
    "    \"\"\"\n",
    "    dataSet = [['y','y','y'],\n",
    "              ['y','y',\"y\"],\n",
    "              ['y','n',\"n\"],\n",
    "              ['n','y',\"n\"],\n",
    "              ['n','y',\"n\"]]\n",
    "    labels = ['no surfacing','flippers','lables']\n",
    "    \n",
    "    return dataSet,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet,labels = loadDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们将其转换成pandas的形式:\n",
    "\n",
    "```python\n",
    "pd.DataFrame```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  no surfacing flippers lables\n",
       "0            y        y      y\n",
       "1            y        y      y\n",
       "2            y        n      n\n",
       "3            n        y      n\n",
       "4            n        y      n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dataSet,columns=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3  Calculate Shannon Ent at labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然我们现在不需要计算整体样本的信息熵(H(labels)),但是我们知道,计算各个特征的信息熵实际上是用各个特征的子特征拆分数据集,统计数量的还是labels列,所以我们需要定义计算labels信息熵的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt_labels(data):\n",
    "    \"\"\"\n",
    "    Calculate ShannonEnt at labels.\n",
    "    Parameters:\n",
    "    ----------\n",
    "        data: pandas of data\n",
    "    Return:\n",
    "    ------\n",
    "        Ent_H_y: ShannonEnt of label.\n",
    "    \"\"\"\n",
    "    allData_size = data.index.size\n",
    "    labels = data.iloc[:,-1]\n",
    "    labels_dict = {}\n",
    "    H_y = []\n",
    "    for label in labels:\n",
    "        if label not in labels_dict:\n",
    "            labels_dict[label] = 1\n",
    "        else:\n",
    "            labels_dict[label] += 1\n",
    "        \n",
    "    for key,value in labels_dict.items():\n",
    "        H_y.append(value)\n",
    "    \n",
    "    H_y_arr = np.array(H_y) /allData_size\n",
    "    Ent_H_y = np.sum(-H_y_arr * np.log2(H_y_arr))\n",
    "    \n",
    "    return Ent_H_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ent of data set labels: 0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "Ent_H_y = calcShannonEnt_labels(data)\n",
    "print('Ent of data set labels:',Ent_H_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Calculate Shannon Ent at features.\n",
    "\n",
    "现在开始进行计算所有的特征的香农熵:\n",
    "\n",
    "(0) 先来回顾不同特征的香农熵是如何计算的:\n",
    "\n",
    "No surfacing:\n",
    "- 1:[is Fish] yes,yes,no \n",
    "- 0:[is Fish] no,no\n",
    "- Entropy(1) = $- \\frac{2}{3} log_{2}\\frac{2}{3} - \\frac{1}{3} log_{2} \\frac{1}{3}=0.918296 $\n",
    "- Entropy(0) = $- 0 - \\frac{2}{2} log_{2} \\frac{2}{2}=0 $\n",
    "- Entropy(No surfacing | Fish) = $\\frac{3}{5}\\times 0.918296 + \\frac{2}{5} \\times 0 = 0.5509$\n",
    "- $\\frac{3}{5},\\frac{2}{5}$: in total dataset\n",
    "\n",
    "(1) 使用不同特征划分样本集,由于我们数据定义的最后一列是labels,所以:\n",
    "\n",
    "```python\n",
    "data.columns[:-1]```\n",
    "\n",
    "(2) 不同特征下的不同子特征划分需要使用到:\n",
    "\n",
    "```python\n",
    "data[data[feature]==feature_son]```\n",
    "\n",
    "(3) 可以使用我们之间定义的calcShannonEnt_labels来计算使用各个特征拆分完成的数据集去计算labels的香农熵.\n",
    "\n",
    "```python\n",
    "calcShannonEnt_labels(feature_data_son)```\n",
    "\n",
    "(4) 计算单个特征的信息熵需要使用总体样本个数和使用单个特征拆分后各个子特征的个数作为权重:\n",
    "\n",
    "定义:```all_data_size = data.index.size```为整体样本个数(也就是$\\frac{3}{5},\\frac{2}{5}$的分母部分)\n",
    "\n",
    "定义:```fenzi_size = feature_data_son.index.size```为各个特征下的子特征的个数(也就是$\\frac{3}{5},\\frac{2}{5}$的分子部分)\n",
    "\n",
    "(5) 计算各个特征下子特征的信息熵Ent_sum,放入best_feature_dict保存,也就是说best_feature_dict中存放的就是各个特征的信息熵.\n",
    "\n",
    "(6) 最后以升序排列字典,那么最小的特征熵,也就是信息增益最大的特征.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt_feature(data):\n",
    "    \"\"\"\n",
    "    Implementation calculate ShannonEnt at feature.\n",
    "    \n",
    "    Prameters:\n",
    "    ---------\n",
    "        data: pandas of data.\n",
    "    Returns:\n",
    "    -------\n",
    "        best_feature: IGmax feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_data_size = data.index.size # get all data size. like 5 in this example.\n",
    "    features_name = data.columns[:-1] # get the feature name. like 2 : 'no surfacing','flippers'\n",
    "    \n",
    "    best_feature_dict = {} # cache shannon ent with every feature.\n",
    "    \n",
    "    for feature in features_name: # star loop feature name.\n",
    "        unique_feature_son = pd.unique(data[feature]) # get subfeatures\n",
    "        \n",
    "        Ent_sum = 0\n",
    "        \n",
    "        for feature_son in unique_feature_son: # loop subfeatures.\n",
    "            \n",
    "            feature_data_son = data[data[feature]==feature_son]# like data[data['no surfacing']=='y']\n",
    "            fenzi_size = feature_data_son.index.size # get molecular part\n",
    "            \n",
    "            # using function calcShannonEnt_labels to calculate shannon Ent\n",
    "            Ent_feature_son = calcShannonEnt_labels(feature_data_son)\n",
    "            \n",
    "            # weights * Ent feature_son:like 3/5 * 0.918296\n",
    "            Ent_sum += Ent_feature_son * fenzi_size / all_data_size\n",
    "\n",
    "        best_feature_dict[feature] = Ent_sum # get single feature shannon ENT.\n",
    "    \n",
    "    best_feature = sorted(best_feature_dict.items(),key=lambda z:z[1]) # sort and get minium ent.\n",
    "    \n",
    "    return best_feature[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature = calcShannonEnt_feature(data)\n",
    "best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到,第一次选择的最优划分特征为:no surfacing\n",
    "\n",
    "得到了最优特征之后我们需要拆分数据集\n",
    "\n",
    "#### 2.5 Split Trees\n",
    "\n",
    "以最优的划分特征来划分数据集,这里需要注意的有一下几点:\n",
    "\n",
    "(1)我们需要统计每次划分使用了多少数据```sum_f```,作为下一部分的退出条件使用(稍后会说明).\n",
    "\n",
    "(2)以最优的特征条件下的子特征划分会有两种结果:\n",
    "\n",
    "(2.1) ```label_size == 1```: 也就是说划分后的节点为叶结点\n",
    "\n",
    "(2.2) 划分后的节点为非叶结点\n",
    "\n",
    "其中非叶结点需要再次调用calcShannonEnt_feature函数对于剩余部分计算最优特征.\n",
    "\n",
    "所以我们定义:\n",
    "\n",
    "当为叶结点的时候,我们无需再次计算calcShannonEnt_feature,而对于非叶结点,我们给予非叶结点的数据以便于再次选取最优特征.\n",
    "\n",
    "这里需要注意的是,对于非叶结点再次计算最优特征,**数据中不能涵盖已经使用过的最优特征**.即:\n",
    "\n",
    "```python\n",
    "data_son.drop(columns=best_feature)```\n",
    "\n",
    "最后次函数将返回两种值:\n",
    "\n",
    "(1) 列表长度为2表示为叶结点,无需再次选取最优节点\n",
    "\n",
    "(2) 列表长度为3表示非叶结点,需要在剩余的数据中再次选择最优的特征.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Trees(data,best_feature):\n",
    "    \"\"\"\n",
    "    split data.\n",
    "    Parameters:\n",
    "    ----------\n",
    "        data: pandas data\n",
    "        best_feature: best feature\n",
    "    \n",
    "    \"\"\"\n",
    "    unique_bf = pd.unique(data[best_feature])\n",
    "    Split_result = []\n",
    "    sum_f = 0\n",
    "    for feature_son in unique_bf:\n",
    "        data_son = data[data[best_feature]==feature_son] # using subfeature to split data.\n",
    "        label_size = pd.unique(data_son.iloc[:,-1]).size\n",
    "        \n",
    "        if label_size == 1:\n",
    "            sum_f += data_son.index.size\n",
    "            Split_result.append([best_feature,feature_son])\n",
    "        else:\n",
    "            drop_data_son = data_son.drop(columns=best_feature) # drop used best feature.\n",
    "            Split_result.append([best_feature,feature_son,drop_data_son])\n",
    "    \n",
    "    return Split_result,sum_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split result is: [['no surfacing', 'y',   flippers lables\n",
      "0        y      y\n",
      "1        y      y\n",
      "2        n      n], ['no surfacing', 'n']]\n",
      "-----------------------------\n",
      "using number of data in best feature: 2\n"
     ]
    }
   ],
   "source": [
    "Split_result,sum_f = split_Trees(data,best_feature)\n",
    "print('split result is:',Split_result)\n",
    "print('-----------------------------')\n",
    "print('using number of data in best feature:',sum_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很明显可以看出最优特征'no surfacing'下的子特征'y'需要再次选取最优条件且再次计算的数据为后面部分(没有no surfacing,因为该特征已经使用过了.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Build DT(ID3)\n",
    "\n",
    "现在开始搭建DT.\n",
    "\n",
    "由于决策树是一种递归,或者说是重复挑选最优特征的过程,所以我们需要定义迭代退出条件:\n",
    "\n",
    "(1) 所有原始样本个数已经被划分完毕\n",
    "\n",
    "这里的**已经被划分完毕**,需要在叶结点下统计,因为只有叶结点才会消耗原始来本数量,非叶结点需要再次挑选最优特征,所以不消耗原始样本特征.\n",
    "\n",
    "也就是split_Trees函数的sum_f.\n",
    "\n",
    "(2) 所有特征已经使用完毕:\n",
    "\n",
    "(2.1) 所有特征使用完毕且样本也已经完全划分完毕\n",
    "\n",
    "(2.2) 所有特征使用完毕,但是样本依然没有划分完毕,这种情况我们一般是对于剩余不能划分完毕的样本取类别出现最多的当做预测类别即函数prob_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_label(data,REST):\n",
    "    \"\"\"\n",
    "    When 2.2\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        data:pandas data\n",
    "        REST: Contains all leaf nodes\n",
    "    Return:\n",
    "    ------\n",
    "        feature_prob: maximum prob label.\n",
    "    \"\"\"\n",
    "    sumOflabels = {}\n",
    "    \n",
    "    # 获取最后未能完全划分的样本\n",
    "    for feature,feature_son in REST:\n",
    "        data = data[data[feature] != feature_son]\n",
    "    \n",
    "    data_labels = data.iloc[:,-1]\n",
    "    # 统计未能完全划分数据的标签个数\n",
    "    for label in data_labels:\n",
    "        if label not in sumOflabels:\n",
    "            sumOflabels[label] = 1\n",
    "        else:\n",
    "            sumOflabels[label] += 1\n",
    "            \n",
    "    # 取出现次数最多的标签作为概率标签\n",
    "    prob_label = sorted(sumOflabels.items(),key=lambda x:x[1],reverse=True)[0][0]\n",
    "    feature_prob = [feature,'!'+feature_son,prob_label] \n",
    "     \n",
    "    return feature_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(data):\n",
    "    \"\"\"\n",
    "    build DT\n",
    "    Parameters:\n",
    "    ----------\n",
    "        data: pandas data\n",
    "    Return:\n",
    "    ------\n",
    "        REST: Contains all leaf nodes\n",
    "        bool: \n",
    "            True:样本划分完毕\n",
    "            False: 样本未划分完毕\n",
    "    \"\"\"\n",
    "    REST = [] # 存放所有的叶结点\n",
    "    ALL_data_size = data.index.size # 获得样本总数\n",
    "    ALL_data_features = data.columns[:-1].size # 获取所有特征数\n",
    "    sum_data = 0\n",
    "    sum_feature = 0\n",
    "    while 1:\n",
    "        # 1.所有样本都已经使用完毕\n",
    "        if sum_data == ALL_data_size:\n",
    "            print('所以样本划分完毕')\n",
    "            return REST,True\n",
    "        # 2.所有特征使用完毕；2.1 样本使用完毕,2.2样本未划分完毕\n",
    "        if sum_feature == ALL_data_features:\n",
    "            if sum_data == ALL_data_size:\n",
    "                print('样本划分完毕')\n",
    "                return REST,True\n",
    "            else:\n",
    "                print('特征已经使用完毕,但是样本依然没有完全划分')\n",
    "                return REST,False\n",
    "        best_feature = calcShannonEnt_feature(data)\n",
    "        sum_feature +=1 # 每得到一个特征 使用特征自加1\n",
    "        Split_result,sum_f = split_Trees(data,best_feature)\n",
    "        sum_data += sum_f\n",
    "        for i in Split_result:\n",
    "            if len(i) == 2: # 判断为叶结点的情况\n",
    "                REST.append(i)\n",
    "            else: # 非叶结点的情况\n",
    "                data = i[-1] # 更新需要再次选择最优条件的数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTrees(data):\n",
    "    \n",
    "    REST,is_ok = DT(data)\n",
    "    if not is_ok:\n",
    "        feature_prob = prob_label(data,REST)\n",
    "        REST.append(feature_prob)\n",
    "        return REST\n",
    "    else:\n",
    "        return REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所以样本划分完毕\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['no surfacing', 'n'], ['flippers', 'y'], ['flippers', 'n']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTrees(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们更改一下数据集就可以获得特征使用完毕,但是样本为划分完毕的情况:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = [['y','y','y'],\n",
    "              ['y','y',\"n\"] , # 更改此处的labels从y变为n\n",
    "              ['y','n',\"n\"],\n",
    "              ['n','y',\"n\"],\n",
    "              ['n','y',\"n\"]]\n",
    "labels = ['no surfacing','flippers','lables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征已经使用完毕,但是样本依然没有完全划分\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['no surfacing', 'n'], ['flippers', 'n'], ['flippers', '!n', 'y']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = pd.DataFrame(dataSet,columns=labels)\n",
    "DecisionTrees(data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的'!n'表示'flippers'特征下的子特征如果不是'n',那么结果大概率是'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.C4.5\n",
    "\n",
    "**信息增益比:**\n",
    "\n",
    "其信息增益与训练数据集的经验熵$H(D)$之比.\n",
    "\n",
    "由于C4.5在生成过程中是采用信息增益比来计算选择特征,所以这里就不在多说了.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.CART\n",
    "\n",
    "CART决策树的生成即使递归地构建二叉决策树的过程,对回归树用平方误差最小化准则,对分类树用基尼指数(Gini index)最小化准则,进行特征选取，生成二叉树.\n",
    "\n",
    "CART生成算法\n",
    "\n",
    "输入:训练数据集D,停止计算的条件\n",
    "\n",
    "输出:CART决策树\n",
    "\n",
    "根据训练数据集,从根节点开始,递归地对每个节点进行一下操作,构建二叉树决策树:\n",
    "\n",
    "(1) 设节点的训练数据集为D,计算现有特征对该数据集的Gini指数.此时,对每个特征A,对其可能取的每个值a,根据样本点A=a的测试为\"是\",\"否\"将D分割成D1和D2两个部分,使用Gini计算A=a的Gini指数\n",
    "\n",
    "(2) 在所有可能的特征A以及它们所有可能的切分点a中,选择Gini指数最小的特征以及对应切分点作为最优特征和最优切分点.依最优特征与最优切分点,从现节点生成两个子节点,将训练数据集依特征分配到两个子节点中去.\n",
    "\n",
    "(3) 对两个子节点递归地调用(1),(2)直到满足停止条件\n",
    "\n",
    "(4) 生成CART\n",
    "\n",
    "\n",
    "**注意:**\n",
    "\n",
    "- $Gini(D,A)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$\n",
    "- $Gini(D) = 1-\\sum_{k=1}^{K}(\\frac{|C_k|}{|D|})^2$\n",
    "- $C_k$是$D$属于第k类的样本子集,K是类的个数\n",
    "\n",
    "- 停止条件:\n",
    "    - 结点中的样本个数小于阈值.\n",
    "    - 样本集的Gini指数小于预订阈值,也就是说样本基本属于同一类.\n",
    "    - 该次样本集中没有更多的特征\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 逻辑阐述\n",
    "\n",
    "1.为了实现CART,这里主要使用pandas这个库，方便处理训练样本\n",
    "\n",
    "2.刚开始调用训练的时候需要初始化一些参数\n",
    "\n",
    "```python\n",
    "self.m,self.n = data.shape \n",
    "self.Dtree = {}\n",
    "self._Gini = np.Inf\n",
    "```\n",
    "\n",
    "3.在参数初始化完毕之后,需要先定义递归退出条件\n",
    "\n",
    "```python\n",
    "\n",
    "if  m <= self.Threshold_data:\n",
    "    print(\"第一个结束条件退出\")\n",
    "return self.Dtree\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "4.接下去就是计算Gin指数获取最优的特征A以及对应的切分点a.\n",
    "\n",
    "```python\n",
    "def calcGini(self,X,labels):\n",
    "    ....\n",
    "```\n",
    "\n",
    "**注意:**这里的计算直接采用向量的形式(因为计算Gini的公式可以转换为向量的形式),并且将$Gini(D,A)$拆分成两个部分\n",
    "\n",
    "5.在计算出最优的Gini得出最优的特征A以及对应的切分点a之后,我们需要依照A=a进行切分\n",
    "\n",
    "```python\n",
    "def split_Tree(self,X,best_label,best_class):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**注意:**虽然我们可以使用A=a进行划分数据集,但是我们并不知道是切分点a的那一侧是叶节点,比如说可能是a的一侧是叶结点,也可能是除了a之外的分割是叶结点,还可能由a划分之后的两个子节点都不是叶结点,还可能是由a分割之后两侧都是叶结点所以我们需要做判断\n",
    "\n",
    "```python\n",
    "if ((X_equal_last_label == X_equal_last_label.iloc[0]).all())...:\n",
    "    ....\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.在数据集划分完毕之后,我们依照上面4中情况进行处理:\n",
    "\n",
    "- 1.A=a划分后两侧都是叶结点,那么可以将其放入最终的字典内\n",
    "- 2.A=a划分后,某一侧是叶结点,但是另外一侧不是,那么我么将是叶结点的那一侧放入最终字典,将不是叶结点的那一侧继续递归\n",
    "- 3.A=a划分后,两侧都不是叶结点的话,那么继续递归,为了结果好看,会创建一个列表来放入子两侧节点的划分结果\n",
    "\n",
    "```python\n",
    "\n",
    "if (res_1 is False) and (res_2 is False)...:\n",
    "    ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.在整体递归结束后,就可以得到最终的字典,另外我们也可以设置停止条件中的阈值来处理过拟合的情况,当然剪枝是最好的操作\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self,Threshold_data=0,Threshold_Gini=0.001,isPrintGini=False):\n",
    "        \n",
    "        self.isPrintGini = isPrintGini\n",
    "        self.Threshold_data = Threshold_data\n",
    "        self.Threshold_Gini = Threshold_Gini\n",
    "        self.is_start = True\n",
    "        self.cache_best_label = None\n",
    "        \n",
    "    def init_args(self,data,labels):\n",
    "        self.m,self.n = data.shape\n",
    "        self.Dtree = {}\n",
    "        self._Gini = np.Inf\n",
    "        \n",
    "    def split_Tree(self,X,best_label,best_class):\n",
    "        \"\"\"\n",
    "        检查叶节点,由于Gini计算出来的best_label,我们不知道到底那一侧是叶节点,所以需要分开来判定\n",
    "        \"\"\"\n",
    "        X_equal_ = X[X[best_label]==best_class]\n",
    "        X_not_equql_ = X[X[best_label]!=best_class]\n",
    "        X_equal_last_label = X_equal_.iloc[:,-1]\n",
    "        X_not_equql_last_label = X_not_equql_.iloc[:,-1]\n",
    "        \n",
    "        if ((X_equal_last_label == X_equal_last_label.iloc[0]).all()) and ((X_not_equql_last_label == X_not_equql_last_label.iloc[0]).all()):\n",
    "            # 说明X_equal_和X_not_equql_为叶节点,也就是说两侧都是叶节点,那么该分支划分完毕\n",
    "            \n",
    "            return False,False\n",
    "        \n",
    "        elif (X_equal_last_label == X_equal_last_label.iloc[0]).all():\n",
    "            #说明X_equal_l是叶节点,那么另一侧就不是应该继续划分\n",
    "            return X_not_equql_,False\n",
    "        \n",
    "        \n",
    "        elif (X_not_equql_last_label == X_not_equql_last_label.iloc[0]).all():\n",
    "            #说明X_not_equql_是叶节点,那么另一侧就不是应该继续划分  \n",
    "            return False,X_equal_\n",
    "        \n",
    "        else:\n",
    "            # 说明两侧都不是,那么两侧都应该继续划分\n",
    "            return X_equal_,X_not_equql_\n",
    "        \n",
    "                \n",
    "    def calcGini(self,X,labels):\n",
    "        res_list = []\n",
    "        for label in labels[:-1]:\n",
    "                \n",
    "            dupli_X = X.drop_duplicates(label)[label]\n",
    "            groupby_X = X.groupby([label,labels[-1]]).size()\n",
    "            \n",
    "            for i in dupli_X:\n",
    "     \n",
    "                #######Gini 第一项 D_1#####\n",
    "                gini_1 = 1-np.sum(np.power(groupby_X[i] /X.groupby([label]).size()[i],2))\n",
    "                Gini_1 = X.groupby([label]).size()[i] / self.m * gini_1\n",
    "                \n",
    "                ########## Gini 第二项 D_2 ########\n",
    "                filter_X = X[X[label] != i]  # 过滤掉含有i的元素\n",
    "                gini_2 = 1- np.sum(np.power(filter_X.groupby(labels[-1]).size() / filter_X.groupby(labels[-1]).size().sum(),2))\n",
    "                Gini_2 = (self.m - X.groupby([label]).size()[i]) / self.m  * gini_2\n",
    "                GINI = Gini_1 + Gini_2\n",
    "                \n",
    "                # 放入列表,用于比较最小Gini值\n",
    "                res_list.append([label,i,GINI])\n",
    "                    \n",
    "                    \n",
    "        # 比较最小Gini值\n",
    "        best_label,best_class,_Gini = sorted(res_list,key=lambda x:x[2])[0]\n",
    "        \n",
    "        return best_label,best_class,_Gini\n",
    "        \n",
    "    \n",
    "    def input_Dtree(self,best_label,best_class):\n",
    "        \n",
    "        if self.cache_best_label is not None:\n",
    "            self.Dtree[self.cache_best_label].append({best_label:best_class})\n",
    "        else:\n",
    "            self.Dtree[best_label] = best_class\n",
    "    \n",
    "    \n",
    "    def fit(self,data,labels):\n",
    "        m = data.shape[0]\n",
    "        \n",
    "        if self.is_start:\n",
    "            self.init_args(data,labels)\n",
    "            self.is_start = False\n",
    "        \n",
    "        # 定义停止条件\n",
    "        if  m <= self.Threshold_data:\n",
    "            print(\"第一个结束条件退出\")\n",
    "            return self.Dtree\n",
    "        \n",
    "        elif self._Gini <= self.Threshold_Gini:\n",
    "            print(\"第二个结束条件退出\")\n",
    "            \n",
    "            return self.Dtree\n",
    "        elif len(labels)-1 == 0:\n",
    "            print(\"第三个结束条件退出\")\n",
    "            \n",
    "            return self.Dtree\n",
    "        \n",
    "        else:\n",
    "            best_label,best_class,self._Gini = self.calcGini(data,labels)\n",
    "                \n",
    "            if self.isPrintGini:\n",
    "                print(\"~Best label:\",best_label,\"~Best class:\",best_class,\"~Caculate Gini:\",self._Gini)\n",
    "                \n",
    "            # 开始划分,如果有一个是叶节点,那么直接是{key:value}的形式,否则{key:{key:{}...}}的形式\n",
    "            res_1,res_2 = self.split_Tree(data,best_label,best_class)\n",
    "            \n",
    "            # 依照A=a不同情况进行结果处理\n",
    "            if (res_1 is False) and (res_2 is False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                \n",
    "            elif (res_1 is not False) and (res_2 is False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                    \n",
    "                data = res_1.drop(columns=[best_label])\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "            elif (res_1 is False) and (res_2 is not False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                    \n",
    "                data = res_2.drop(columns=[best_label])\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "            elif (res_1 is not False) and (res_2 is not False):\n",
    "                \n",
    "                self.Dtree[best_label+\":\"+best_class] = []\n",
    "                self.cache_best_label = best_label+\":\"+best_class\n",
    "                print(\"{}:{} 子分支第一个\".format(best_label,best_class))\n",
    "                \n",
    "                data = res_1\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "                self.Dtree[best_label+\":not \"+best_class] = []\n",
    "                self.cache_best_label = best_label+\":not \"+best_class\n",
    "                \n",
    "                print(\"{}:not {} 子分支第二个\".format(best_label,best_class))\n",
    "                \n",
    "                data = res_2\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                self.cache_best_label = None\n",
    "                \n",
    "        return self.Dtree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 尝试统计学习方法(李航)例子5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    datasets = np.array([\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ])\n",
    "    labels = np.array(['年龄', '有工作', '有自己的房子', '信贷情况', '类别'])\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=datasets,columns=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2 = CART(isPrintGini=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Best label: 有自己的房子 ~Best class: 否 ~Caculate Gini: 0.26666666666666666\n",
      "~Best label: 有工作 ~Best class: 否 ~Caculate Gini: 0.0\n",
      "{'有自己的房子': '否', '有工作': '否'}\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.DataFrame(data=datasets,columns=labels)\n",
    "Dtree = cart2.fit(data_test,labels)\n",
    "print(Dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到结果是正确的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 再来尝试机器学习实战中的案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingDataSet():\n",
    "    \"\"\"\n",
    "    Implement predict contact lens\n",
    "    returns:\n",
    "        lenesTree\n",
    "    \"\"\"\n",
    "    path = \"data_set/lenses.txt\"\n",
    "    fr = open(path)\n",
    "    lenses = np.array([inst.strip().split('\\t') for inst in fr.readlines() ])\n",
    "    lenesLabels = ['age','prescript','astigmatic','tearRate','Joker']\n",
    "    return lenses,lenesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>prescript</th>\n",
       "      <th>astigmatic</th>\n",
       "      <th>tearRate</th>\n",
       "      <th>Joker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age prescript astigmatic tearRate      Joker\n",
       "0        young     myope         no  reduced  no lenses\n",
       "1        young     myope         no   normal       soft\n",
       "2        young     myope        yes  reduced  no lenses\n",
       "3        young     myope        yes   normal       hard\n",
       "4        young     hyper         no  reduced  no lenses\n",
       "5        young     hyper         no   normal       soft\n",
       "6        young     hyper        yes  reduced  no lenses\n",
       "7        young     hyper        yes   normal       hard\n",
       "8          pre     myope         no  reduced  no lenses\n",
       "9          pre     myope         no   normal       soft\n",
       "10         pre     myope        yes  reduced  no lenses\n",
       "11         pre     myope        yes   normal       hard\n",
       "12         pre     hyper         no  reduced  no lenses\n",
       "13         pre     hyper         no   normal       soft\n",
       "14         pre     hyper        yes  reduced  no lenses\n",
       "15         pre     hyper        yes   normal  no lenses\n",
       "16  presbyopic     myope         no  reduced  no lenses\n",
       "17  presbyopic     myope         no   normal  no lenses\n",
       "18  presbyopic     myope        yes  reduced  no lenses\n",
       "19  presbyopic     myope        yes   normal       hard\n",
       "20  presbyopic     hyper         no  reduced  no lenses\n",
       "21  presbyopic     hyper         no   normal       soft\n",
       "22  presbyopic     hyper        yes  reduced  no lenses\n",
       "23  presbyopic     hyper        yes   normal  no lenses"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenses,lenesLabels = loadingDataSet()\n",
    "data_lenses = pd.DataFrame(data=lenses,columns=lenesLabels)\n",
    "data_lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2 = CART(isPrintGini=True,Threshold_Gini=-np.Inf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Best label: tearRate ~Best class: reduced ~Caculate Gini: 0.3263888888888889\n",
      "~Best label: astigmatic ~Best class: yes ~Caculate Gini: 0.31944444444444436\n",
      "astigmatic:yes 子分支第一个\n",
      "~Best label: prescript ~Best class: hyper ~Caculate Gini: 0.05555555555555555\n",
      "~Best label: age ~Best class: young ~Caculate Gini: 0.0\n",
      "astigmatic:not yes 子分支第二个\n",
      "~Best label: age ~Best class: presbyopic ~Caculate Gini: 0.041666666666666664\n",
      "~Best label: prescript ~Best class: myope ~Caculate Gini: 0.0\n",
      "{'tearRate': 'reduced', 'astigmatic:yes': [{'prescript': 'hyper'}, {'age': 'young'}], 'astigmatic:not yes': [{'age': 'presbyopic'}, {'prescript': 'myope'}]}\n"
     ]
    }
   ],
   "source": [
    "Dtree = cart2.fit(data_lenses,lenesLabels)\n",
    "print(Dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原题分割结果如下:\n",
    "![](picture/tree_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出结果是一模一样的,但是这里不够的是,并没有采取剪枝措施.\n",
    "\n",
    "CART剪枝:**统计学方法**P73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "[sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "[sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意,由于scikit使用的数据形式与之前我们创建的形式有差异,所以我们并不能使用scikit去检验我们例子的结果,当然你也可以更改例子中的数据形式来尝试\n",
    "\n",
    "scikit 数据形式:\n",
    "\n",
    "```\n",
    "X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.\n",
    "\n",
    "y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
    "The target values (class labels) as integers or strings.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf, out_file=\"picture/mytree.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将dot转换为png文件需要安装[graphviz](https://www.graphviz.org/download/)\n",
    "使用[sklearn.tree.export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html)中的\n",
    "\n",
    "```\n",
    "$ dot -Tps tree.dot -o tree.ps  (PostScript format) \n",
    "$ dot -Tpng tree.dot -o tree.png    (PNG format)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](picture/mytree.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
