{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisionn Trees\n",
    "![](picture/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if every item in the dataset is in the same class:\n",
    "\n",
    "    if so return the class label\n",
    "    Else\n",
    "        find the best feature to split the data\n",
    "        split the dataset\n",
    "        create a branch node\n",
    "             for each split\n",
    "                 call createBranch and add the result to the branch node\n",
    "             retuen branch node\n",
    "             \n",
    "Please note the recursive nature of createBranch. It calls itself in the second-to-last line.\n",
    "\n",
    "**Note:** some decision trees make a binary split of the data,but we won't do this. We'll follow the ID3 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3\n",
    "\n",
    "Entropy is defined as the expected value of the information. First, we need to define information. If you’re classifying something that can take on multiple values, the information for symbol xi is defined as\n",
    "\n",
    "$l(x_i) = log_{2}p(x_i)$\n",
    "\n",
    "where p(xi) is the probability of choosing this class.\n",
    "\n",
    "To calculate entropy, you need the expected value of all the information of all pos-\n",
    "sible values of our class. This is given by\n",
    "\n",
    "$H = - \\sum_{i=1}^{n}p(x_i)log_{2}p(x_i)$\n",
    "\n",
    "where n is the number of classes.\n",
    "\n",
    "Note: click [here](https://blog.csdn.net/acdreamers/article/details/44661149) to ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "\n",
    "See the data in table 3.1. It contains five animals pulled from the sea and asks if they can survive without coming to the surface and if they have flippers. We would like to classify these animals into two classes: fish and not fish. Now we want to decide whether we should split the data based on the first feature or the second feature. To answer this question, we need some quantitative way of determining how to split the data. We’ll discuss that next.\n",
    "\n",
    "![](picture/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look how to compute SannonENT\n",
    "\n",
    "If we target learnning \"is Fish?\".\n",
    "\n",
    "The table 3.1 total examples is 5, and 2 \"yes\",3 \"no\". So,we compute shannonENT as follows\n",
    "\n",
    "$H = - \\frac{3}{5} log_{2}\\frac{3}{5} - \\frac{2}{5} log_{2} \\frac{2}{5} = 0.9709505944546686$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Function to calculate the Shannon entropy of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    parameter-- dataSet,it's a dictionary\n",
    "    \n",
    "    return shannon Ent\n",
    "    \"\"\"\n",
    "    numEntrise = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "            labelCounts[currentLabel] += 1\n",
    "        else:\n",
    "            labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.\n",
    "#     print(labelCounts)\n",
    "    for key in labelCounts:\n",
    "        # compute shannon entropy \n",
    "        prob = float(labelCounts[key]) /  numEntrise\n",
    "        shannonEnt -= prob * log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    \"\"\"\n",
    "    create data set with table 3.1 Marine animal data\n",
    "    Note: 1 = Yes ,0= No in fetures.\n",
    "    returns-- data set and labels\n",
    "    \"\"\"\n",
    "    dataSet = [[1,1,'yes'],\n",
    "              [1,1,\"yes\"],\n",
    "              [1,0,\"no\"],\n",
    "              [0,1,\"no\"],\n",
    "              [0,1,\"no\"]]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    return dataSet,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try compute shannonENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "dataSet,labels = createDataSet()\n",
    "shannonENT = calcShannonEnt(dataSet)\n",
    "print(shannonENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Splitting the dataset\n",
    "You just saw how to measure the amount of disorder in a dataset. For our classifier algorithm to work, you need to measure the entropy, split the dataset, measure the entropy on the split sets, and see if splitting it was the right thing to do. You’ll do this for all of our features to determine the best feature to split on. Think of it as a two- dimensional plot of some data. You want to draw a line to separate one class from another. Should you do this on the X-axis or the Y-axis? The answer is what you’re try- ing to find out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    \"\"\"\n",
    "    Dataset splitting on given feture\n",
    "    \n",
    "    returns : retDataSet\n",
    "    \"\"\"\n",
    "    \n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        # start split dataset\n",
    "        if featVec[axis] == value: # if value of featVec[axis] equal target value, then  append to retDataSet\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n"
     ]
    }
   ],
   "source": [
    "dataSet,labels = createDataSet()\n",
    "print(dataSet)\n",
    "retDataSet = splitDataSet(dataSet,0,1)\n",
    "print(retDataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re now going to combine the Shannon entropy calculation and the splitDataSet() function to cycle through the dataset and decide which feature is the best to split on. Using the entropy calculation tells you which split best organizes your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Choosing the best feature to split on\n",
    "\n",
    "在决策树的每一个非叶子结点划分之前，先计算每一个属性所带来的信息增益，选择最大信息增益的属性来划\n",
    "分，因为信息增益越大，区分样本的能力就越强，越具有代表性，很显然这是一种自顶向下的贪心策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    choose the best feture to spilt\n",
    "    \n",
    "    return:\n",
    "        bestFeture\n",
    "    \"\"\"\n",
    "    # get Number of index in every feature list.Note: every feature list must be same.\n",
    "    numFeatures = len(dataSet[0]) -1 \n",
    "    # compute \"is Fish\" feature  base entropy,like example in \"dataSet cell\".\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    # set best InfoGain, infoGain is Swedish language~,initialize value equal 0\n",
    "    # and set best feature. initialize value equal -1\n",
    "    bestInfoGain = 0.; bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet] #get every feature list\n",
    "        uniqueVals = set(featList) # unique feature list\n",
    "        newEntropy = 0.\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            \n",
    "            # follows code about 2 lines, compute shannonEnt.\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            \n",
    "        infoGain = baseEntropy - newEntropy # comput infoGain\n",
    "        if (infoGain > bestInfoGain): # update infoGain\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i  # update best feature\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "Best Feature index is  0\n"
     ]
    }
   ],
   "source": [
    "dataSet,labels = createDataSet()\n",
    "print(dataSet)\n",
    "bestFeature = chooseBestFeatureToSplit(dataSet)\n",
    "print(\"Best Feature index is \",bestFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So,the Best Feature is \"Can survive without coming to surface.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You’ll stop under the following conditions: you run out of attributes on which to split or all the instances in a branch are the same class. If all instances have the same class, then you’ll create a leaf node, or terminating block. Any data that reaches this leaf node is deemed to belong to the class of that leaf node. \n",
    "![](picture/03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Befor we create the Decision Tree,we need learning decision tree's logist.\n",
    "\n",
    "Let's look what is decision tree's logist.\n",
    "\n",
    "We using this example dataset\n",
    "\n",
    "![](picture/04.png)\n",
    "\n",
    "\n",
    "- step 1: we need compute Entropy(Fish) = $- \\frac{3}{5} log_{2}\\frac{3}{5} - \\frac{2}{5} log_{2} \\frac{2}{5}=0.9709505944546686$\n",
    "- step 2: comput IG\n",
    "    - No surfacing:\n",
    "        - 1:[is Fish] yes,yes,no \n",
    "        - 0:[is Fish] no,no\n",
    "        - Entropy(1) = $- \\frac{2}{3} log_{2}\\frac{2}{3} - \\frac{1}{3} log_{2} \\frac{1}{3}=0.918296 $\n",
    "        - Entropy(0) = $- 0 - \\frac{2}{2} log_{2} \\frac{2}{2}=0 $\n",
    "        - Entropy(No surfacing | Fish) = $\\frac{3}{5}\\times 0.918296 + \\frac{2}{5} \\times 0 = 0.5509$\n",
    "        - $\\frac{3}{5},\\frac{2}{5}$: in total dataset\n",
    "        - IG(No surfacing | Fish) = 0.9709505944546686 - 0.5509 = 0.42\n",
    "    - Flippers:\n",
    "        - 1:[is Fish] yes,yes,no,no\n",
    "        - 0:[is Fish] no\n",
    "        - Entropy(1) = $- \\frac{2}{4} log_{2}\\frac{2}{4} - \\frac{2}{4} log_{2} \\frac{2}{4}=1.0 $\n",
    "        - Entropy(0) = $- 0 - \\frac{1}{1} log_{2} \\frac{1}{1}=0 $\n",
    "        - Entropy(Flippers | Fish) = $\\frac{4}{5}\\times 1 + \\frac{1}{5} \\times 0 = 0.8$\n",
    "        - $\\frac{1}{5},\\frac{4}{5}$: in total dataset\n",
    "        - IG(Flippers | Fish) = 0.9709505944546686 - 0.8 = 0.17095\n",
    "        \n",
    "- step 3: choose best IG(max IG)\n",
    "    - so,we choose feature \"No surfacing\".\n",
    "- step 4: using feature \"No surfacing\" to split dataset.\n",
    "- step 5: repeat like setp 1-3\n",
    "    \n",
    "**Last Note:**\n",
    " - if best feature can't split dataset to  have same class label, then ,can using other feature to split dataset.\n",
    "     - [[1, 1, 'yes'], [1, 0, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]\n",
    " \n",
    " - if case have no more features to split, but we also can't split dataset to have same class label, then we use \"majority vote.\"\n",
    "     - [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): \n",
    "            classCount[vote] = 0\n",
    "        else:\n",
    "            classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    print(sortedClassCount)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 2), ('no', 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majorityCnt(['yes','yes','yes','no'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Tree-building code\n",
    "\n",
    "The first stopping condition is that if all the class labels are the same, then you return this label.\n",
    "\n",
    "The second stopping condition is the case when there are no more features to split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    # get class list: [\"yes\",\"yes\"..] in last feature.\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    \n",
    "    # define first stopping condition.\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        \n",
    "        return classList[0]\n",
    "    \n",
    "    # define second stopping condition.\n",
    "    if len(dataSet[0]) == 1:\n",
    "        \n",
    "        return  majorityCnt(classList)\n",
    "    \n",
    "    # get best Feature.\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    \n",
    "    # using best feture to get label in labels.\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    \n",
    "    # create result tree.\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    \n",
    "    del (labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues) # get unique values to split dataset.\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:] # Get the remaining tables.\n",
    "        # start Recursive.\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "['no surfacing', 'flippers']\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "dataSet,labels = createDataSet()\n",
    "print(dataSet)\n",
    "print(labels)\n",
    "myTree = createTree(dataSet,labels)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 0), ('no', 0)]\n",
      "{'flippers': {0: 'no', 1: {'no surfacing': {0: 'yes', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]\n",
    "labels = ['no surfacing', 'flippers']\n",
    "myTree = createTree(dataSet,labels)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best feature can't split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 0), ('no', 0)]\n",
      "{'no surfacing': {0: {'flippers': {'yes': 'yes', 'no': 'no'}}, 1: {'flippers': {0: 'yes', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "dataSet = [[1, 1, 'yes'], [1, 0, 'yes'], [1, 0, 'no'], [0, 1, 'yes'], [0, 1, 'no']]\n",
    "labels = ['no surfacing', 'flippers']\n",
    "myTree = createTree(dataSet,labels)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.using decision trees to predict contact lens type\n",
    "\n",
    "The Lenses dataset3 is one of the more famous datasets. It’s a number of observations based on patients’ eye conditions and the type of contact lenses the doctor prescribed. The classes are hard, soft, and no contact lenses. The data is from the UCI database repository and is modified slightly so that it can be displayed easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingDataSet():\n",
    "    \"\"\"\n",
    "    Implement predict contact lens\n",
    "    returns:\n",
    "        lenesTree\n",
    "    \"\"\"\n",
    "    path = \"data_set/lenses.txt\"\n",
    "    fr = open(path)\n",
    "    lenses = [inst.strip().split('\\t') for inst in fr.readlines() ]\n",
    "    lenesLabels = ['age','prescript','astigmatic','tearRate']\n",
    "    lenesTree = createTree(lenses,lenesLabels)\n",
    "    return lenesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'young': 'hard', 'pre': 'no lenses', 'presbyopic': 'no lenses'}}, 'myope': 'hard'}}, 'no': {'age': {'young': 'soft', 'pre': 'soft', 'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "lenesTree = loadingDataSet()\n",
    "print(lenesTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.C4.5\n",
    "\n",
    "**信息增益比:**\n",
    "\n",
    "其信息增益与训练数据集的经验熵$H(D)$之比.\n",
    "\n",
    "由于C4.5在生成过程中是采用信息增益比来计算选择特征,所以这里就不在多说了.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.CART\n",
    "\n",
    "CART决策树的生成即使递归地构建二叉决策树的过程,对回归树用平方误差最小化准则,对分类树用基尼指数(Gini index)最小化准则,进行特征选取，生成二叉树.\n",
    "\n",
    "CART生成算法\n",
    "\n",
    "输入:训练数据集D,停止计算的条件\n",
    "\n",
    "输出:CART决策树\n",
    "\n",
    "根据训练数据集,从根节点开始,递归地对每个节点进行一下操作,构建二叉树决策树:\n",
    "\n",
    "(1) 设节点的训练数据集为D,计算现有特征对该数据集的Gini指数.此时,对每个特征A,对其可能取的每个值a,根据样本点A=a的测试为\"是\",\"否\"将D分割成D1和D2两个部分,使用Gini计算A=a的Gini指数\n",
    "\n",
    "(2) 在所有可能的特征A以及它们所有可能的切分点a中,选择Gini指数最小的特征以及对应切分点作为最优特征和最优切分点.依最优特征与最优切分点,从现节点生成两个子节点,将训练数据集依特征分配到两个子节点中去.\n",
    "\n",
    "(3) 对两个子节点递归地调用(1),(2)直到满足停止条件\n",
    "\n",
    "(4) 生成CART\n",
    "\n",
    "\n",
    "**注意:**\n",
    "\n",
    "- $Gini(D,A)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$\n",
    "- $Gini(D) = 1-\\sum_{k=1}^{K}(\\frac{|C_k|}{|D|})^2$\n",
    "- $C_k$是$D$属于第k类的样本子集,K是类的个数\n",
    "\n",
    "- 停止条件:\n",
    "    - 结点中的样本个数小于阈值.\n",
    "    - 样本集的Gini指数小于预订阈值,也就是说样本基本属于同一类.\n",
    "    - 该次样本集中没有更多的特征\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 逻辑阐述\n",
    "\n",
    "1.为了实现CART,这里主要使用pandas这个库，方便处理训练样本\n",
    "\n",
    "2.刚开始调用训练的时候需要初始化一些参数\n",
    "\n",
    "```python\n",
    "self.m,self.n = data.shape \n",
    "self.Dtree = {}\n",
    "self._Gini = np.Inf\n",
    "```\n",
    "\n",
    "3.在参数初始化完毕之后,需要先定义递归退出条件\n",
    "\n",
    "```python\n",
    "\n",
    "if  m <= self.Threshold_data:\n",
    "    print(\"第一个结束条件退出\")\n",
    "return self.Dtree\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "4.接下去就是计算Gin指数获取最优的特征A以及对应的切分点a.\n",
    "\n",
    "```python\n",
    "def calcGini(self,X,labels):\n",
    "    ....\n",
    "```\n",
    "\n",
    "**注意:**这里的计算直接采用向量的形式(因为计算Gini的公式可以转换为向量的形式),并且将$Gini(D,A)$拆分成两个部分\n",
    "\n",
    "5.在计算出最优的Gini得出最优的特征A以及对应的切分点a之后,我们需要依照A=a进行切分\n",
    "\n",
    "```python\n",
    "def split_Tree(self,X,best_label,best_class):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**注意:**虽然我们可以使用A=a进行划分数据集,但是我们并不知道是切分点a的那一侧是叶节点,比如说可能是a的一侧是叶结点,也可能是除了a之外的分割是叶结点,还可能由a划分之后的两个子节点都不是叶结点,还可能是由a分割之后两侧都是叶结点所以我们需要做判断\n",
    "\n",
    "```python\n",
    "if ((X_equal_last_label == X_equal_last_label.iloc[0]).all())...:\n",
    "    ....\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.在数据集划分完毕之后,我们依照上面4中情况进行处理:\n",
    "\n",
    "- 1.A=a划分后两侧都是叶结点,那么可以将其放入最终的字典内\n",
    "- 2.A=a划分后,某一侧是叶结点,但是另外一侧不是,那么我么将是叶结点的那一侧放入最终字典,将不是叶结点的那一侧继续递归\n",
    "- 3.A=a划分后,两侧都不是叶结点的话,那么继续递归,为了结果好看,会创建一个列表来放入子两侧节点的划分结果\n",
    "\n",
    "```python\n",
    "\n",
    "if (res_1 is False) and (res_2 is False)...:\n",
    "    ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.在整体递归结束后,就可以得到最终的字典,另外我们也可以设置停止条件中的阈值来处理过拟合的情况,当然剪枝是最好的操作\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self,Threshold_data=0,Threshold_Gini=0.001,isPrintGini=False):\n",
    "        \n",
    "        self.isPrintGini = isPrintGini\n",
    "        self.Threshold_data = Threshold_data\n",
    "        self.Threshold_Gini = Threshold_Gini\n",
    "        self.is_start = True\n",
    "        self.cache_best_label = None\n",
    "        \n",
    "    def init_args(self,data,labels):\n",
    "        self.m,self.n = data.shape\n",
    "        self.Dtree = {}\n",
    "        self._Gini = np.Inf\n",
    "        \n",
    "    def split_Tree(self,X,best_label,best_class):\n",
    "        \"\"\"\n",
    "        检查叶节点,由于Gini计算出来的best_label,我们不知道到底那一侧是叶节点,所以需要分开来判定\n",
    "        \"\"\"\n",
    "        X_equal_ = X[X[best_label]==best_class]\n",
    "        X_not_equql_ = X[X[best_label]!=best_class]\n",
    "        X_equal_last_label = X_equal_.iloc[:,-1]\n",
    "        X_not_equql_last_label = X_not_equql_.iloc[:,-1]\n",
    "        \n",
    "        if ((X_equal_last_label == X_equal_last_label.iloc[0]).all()) and ((X_not_equql_last_label == X_not_equql_last_label.iloc[0]).all()):\n",
    "            # 说明X_equal_和X_not_equql_为叶节点,也就是说两侧都是叶节点,那么该分支划分完毕\n",
    "            \n",
    "            return False,False\n",
    "        \n",
    "        elif (X_equal_last_label == X_equal_last_label.iloc[0]).all():\n",
    "            #说明X_equal_l是叶节点,那么另一侧就不是应该继续划分\n",
    "            return X_not_equql_,False\n",
    "        \n",
    "        \n",
    "        elif (X_not_equql_last_label == X_not_equql_last_label.iloc[0]).all():\n",
    "            #说明X_not_equql_是叶节点,那么另一侧就不是应该继续划分  \n",
    "            return False,X_equal_\n",
    "        \n",
    "        else:\n",
    "            # 说明两侧都不是,那么两侧都应该继续划分\n",
    "            return X_equal_,X_not_equql_\n",
    "        \n",
    "                \n",
    "    def calcGini(self,X,labels):\n",
    "        res_list = []\n",
    "        for label in labels[:-1]:\n",
    "                \n",
    "            dupli_X = X.drop_duplicates(label)[label]\n",
    "            groupby_X = X.groupby([label,labels[-1]]).size()\n",
    "            \n",
    "            for i in dupli_X:\n",
    "     \n",
    "                #######Gini 第一项 D_1#####\n",
    "                gini_1 = 1-np.sum(np.power(groupby_X[i] /X.groupby([label]).size()[i],2))\n",
    "                Gini_1 = X.groupby([label]).size()[i] / self.m * gini_1\n",
    "                \n",
    "                ########## Gini 第二项 D_2 ########\n",
    "                filter_X = X[X[label] != i]  # 过滤掉含有i的元素\n",
    "                gini_2 = 1- np.sum(np.power(filter_X.groupby(labels[-1]).size() / filter_X.groupby(labels[-1]).size().sum(),2))\n",
    "                Gini_2 = (self.m - X.groupby([label]).size()[i]) / self.m  * gini_2\n",
    "                GINI = Gini_1 + Gini_2\n",
    "                \n",
    "                # 放入列表,用于比较最小Gini值\n",
    "                res_list.append([label,i,GINI])\n",
    "                    \n",
    "                    \n",
    "        # 比较最小Gini值\n",
    "        best_label,best_class,_Gini = sorted(res_list,key=lambda x:x[2])[0]\n",
    "        \n",
    "        return best_label,best_class,_Gini\n",
    "        \n",
    "    \n",
    "    def input_Dtree(self,best_label,best_class):\n",
    "        \n",
    "        if self.cache_best_label is not None:\n",
    "            self.Dtree[self.cache_best_label].append({best_label:best_class})\n",
    "        else:\n",
    "            self.Dtree[best_label] = best_class\n",
    "    \n",
    "    \n",
    "    def fit(self,data,labels):\n",
    "        m = data.shape[0]\n",
    "        \n",
    "        if self.is_start:\n",
    "            self.init_args(data,labels)\n",
    "            self.is_start = False\n",
    "        \n",
    "        # 定义停止条件\n",
    "        if  m <= self.Threshold_data:\n",
    "            print(\"第一个结束条件退出\")\n",
    "            return self.Dtree\n",
    "        \n",
    "        elif self._Gini <= self.Threshold_Gini:\n",
    "            print(\"第二个结束条件退出\")\n",
    "            \n",
    "            return self.Dtree\n",
    "        elif len(labels)-1 == 0:\n",
    "            print(\"第三个结束条件退出\")\n",
    "            \n",
    "            return self.Dtree\n",
    "        \n",
    "        else:\n",
    "            best_label,best_class,self._Gini = self.calcGini(data,labels)\n",
    "                \n",
    "            if self.isPrintGini:\n",
    "                print(\"~Best label:\",best_label,\"~Best class:\",best_class,\"~Caculate Gini:\",self._Gini)\n",
    "                \n",
    "            # 开始划分,如果有一个是叶节点,那么直接是{key:value}的形式,否则{key:{key:{}...}}的形式\n",
    "            res_1,res_2 = self.split_Tree(data,best_label,best_class)\n",
    "            \n",
    "            # 依照A=a不同情况进行结果处理\n",
    "            if (res_1 is False) and (res_2 is False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                \n",
    "            elif (res_1 is not False) and (res_2 is False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                    \n",
    "                data = res_1.drop(columns=[best_label])\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "            elif (res_1 is False) and (res_2 is not False):\n",
    "                \n",
    "                self.input_Dtree(best_label,best_class)\n",
    "                    \n",
    "                data = res_2.drop(columns=[best_label])\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "            elif (res_1 is not False) and (res_2 is not False):\n",
    "                \n",
    "                self.Dtree[best_label+\":\"+best_class] = []\n",
    "                self.cache_best_label = best_label+\":\"+best_class\n",
    "                print(\"{}:{} 子分支第一个\".format(best_label,best_class))\n",
    "                \n",
    "                data = res_1\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                \n",
    "                self.Dtree[best_label+\":not \"+best_class] = []\n",
    "                self.cache_best_label = best_label+\":not \"+best_class\n",
    "                \n",
    "                print(\"{}:not {} 子分支第二个\".format(best_label,best_class))\n",
    "                \n",
    "                data = res_2\n",
    "                labels = data.columns\n",
    "                self.fit(data,labels)\n",
    "                self.cache_best_label = None\n",
    "                \n",
    "        return self.Dtree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 尝试统计学习方法(李航)例子5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    datasets = np.array([\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ])\n",
    "    labels = np.array(['年龄', '有工作', '有自己的房子', '信贷情况', '类别'])\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=datasets,columns=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2 = CART(isPrintGini=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Best label: 有自己的房子 ~Best class: 否 ~Caculate Gini: 0.26666666666666666\n",
      "~Best label: 有工作 ~Best class: 否 ~Caculate Gini: 0.0\n",
      "{'有自己的房子': '否', '有工作': '否'}\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.DataFrame(data=datasets,columns=labels)\n",
    "Dtree = cart2.fit(data_test,labels)\n",
    "print(Dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到结果是正确的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 再来尝试机器学习实战中的案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingDataSet():\n",
    "    \"\"\"\n",
    "    Implement predict contact lens\n",
    "    returns:\n",
    "        lenesTree\n",
    "    \"\"\"\n",
    "    path = \"data_set/lenses.txt\"\n",
    "    fr = open(path)\n",
    "    lenses = np.array([inst.strip().split('\\t') for inst in fr.readlines() ])\n",
    "    lenesLabels = ['age','prescript','astigmatic','tearRate','Joker']\n",
    "    return lenses,lenesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>prescript</th>\n",
       "      <th>astigmatic</th>\n",
       "      <th>tearRate</th>\n",
       "      <th>Joker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>young</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pre</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pre</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hyper</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>no lenses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age prescript astigmatic tearRate      Joker\n",
       "0        young     myope         no  reduced  no lenses\n",
       "1        young     myope         no   normal       soft\n",
       "2        young     myope        yes  reduced  no lenses\n",
       "3        young     myope        yes   normal       hard\n",
       "4        young     hyper         no  reduced  no lenses\n",
       "5        young     hyper         no   normal       soft\n",
       "6        young     hyper        yes  reduced  no lenses\n",
       "7        young     hyper        yes   normal       hard\n",
       "8          pre     myope         no  reduced  no lenses\n",
       "9          pre     myope         no   normal       soft\n",
       "10         pre     myope        yes  reduced  no lenses\n",
       "11         pre     myope        yes   normal       hard\n",
       "12         pre     hyper         no  reduced  no lenses\n",
       "13         pre     hyper         no   normal       soft\n",
       "14         pre     hyper        yes  reduced  no lenses\n",
       "15         pre     hyper        yes   normal  no lenses\n",
       "16  presbyopic     myope         no  reduced  no lenses\n",
       "17  presbyopic     myope         no   normal  no lenses\n",
       "18  presbyopic     myope        yes  reduced  no lenses\n",
       "19  presbyopic     myope        yes   normal       hard\n",
       "20  presbyopic     hyper         no  reduced  no lenses\n",
       "21  presbyopic     hyper         no   normal       soft\n",
       "22  presbyopic     hyper        yes  reduced  no lenses\n",
       "23  presbyopic     hyper        yes   normal  no lenses"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenses,lenesLabels = loadingDataSet()\n",
    "data_lenses = pd.DataFrame(data=lenses,columns=lenesLabels)\n",
    "data_lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2 = CART(isPrintGini=True,Threshold_Gini=-np.Inf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Best label: tearRate ~Best class: reduced ~Caculate Gini: 0.3263888888888889\n",
      "~Best label: astigmatic ~Best class: yes ~Caculate Gini: 0.31944444444444436\n",
      "astigmatic:yes 子分支第一个\n",
      "~Best label: prescript ~Best class: hyper ~Caculate Gini: 0.05555555555555555\n",
      "~Best label: age ~Best class: young ~Caculate Gini: 0.0\n",
      "astigmatic:not yes 子分支第二个\n",
      "~Best label: age ~Best class: presbyopic ~Caculate Gini: 0.041666666666666664\n",
      "~Best label: prescript ~Best class: myope ~Caculate Gini: 0.0\n",
      "{'tearRate': 'reduced', 'astigmatic:yes': [{'prescript': 'hyper'}, {'age': 'young'}], 'astigmatic:not yes': [{'age': 'presbyopic'}, {'prescript': 'myope'}]}\n"
     ]
    }
   ],
   "source": [
    "Dtree = cart2.fit(data_lenses,lenesLabels)\n",
    "print(Dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原题分割结果如下:\n",
    "![](picture/tree_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出结果是一模一样的,但是这里不够的是,并没有采取剪枝措施.\n",
    "\n",
    "CART剪枝:**统计学方法**P73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "[sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "[sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意,由于scikit使用的数据形式与之前我们创建的形式有差异,所以我们并不能使用scikit去检验我们例子的结果,当然你也可以更改例子中的数据形式来尝试\n",
    "\n",
    "scikit 数据形式:\n",
    "\n",
    "```\n",
    "X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.\n",
    "\n",
    "y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
    "The target values (class labels) as integers or strings.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf, out_file=\"picture/mytree.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将dot转换为png文件需要安装[graphviz](https://www.graphviz.org/download/)\n",
    "使用[sklearn.tree.export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html)中的\n",
    "\n",
    "```\n",
    "$ dot -Tps tree.dot -o tree.ps  (PostScript format) \n",
    "$ dot -Tpng tree.dot -o tree.png    (PNG format)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](picture/mytree.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
